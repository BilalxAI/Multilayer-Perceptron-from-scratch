# Multilayer-Perceptron-from-scratch
# How implement a Multilayer Perceptron
Artificial neural networks (ANNs) or connectionist systems are computing systems inspired by the biological neural networks that constitute animal brains. Such systems learn (progressively improve performance) to do tasks by considering examples, generally without task-specific programming. For example, in image recognition, "they might learn to identify images that contain cats by analyzing example images that have been manually labeled as "cat" or "no cat" and using the analytic results to identify cats in other images".

They have found most use in applications difficult to express in a traditional computer algorithm using rule-based programming. An ANN is based on a collection of connected units called artificial neurons, (analogous to axons in a biological brain). Each connection (synapse) between neurons can transmit a signal to another neuron. The receiving (postsynaptic) neuron can process the signal(s) and then signal downstream neurons connected to it.

More information here: [Artificial Neural Network](https://en.wikipedia.org/wiki/Artificial_neural_network)

How does Multilayer Perceptron work?Â¶
We can summarize the operation of the perceptron as follows it:

Step 1: Initialize the weights and bias with small-randomized values;
Step 2: Propagate all values in the input layer until output layer(Forward Propagation)
Step 3: Update weight and bias in the inner layers(Backpropagation)
Step 4: Do it until that the stop criterion is satisfied !
![image](https://github.com/BilalxAI/Multilayer-Perceptron-from-scratch/assets/97829564/73d4520c-743d-4ee0-b9c0-05215fb89d3d
